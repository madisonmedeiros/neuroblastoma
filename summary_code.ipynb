{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code was used to evaluate the results generated by RV EXCALIBER. Here we validate the burden matrix has the correct variants for each patient. Along with validating allele counts generated by RV EXCALIBER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1 \n",
    "\n",
    "Step 1 loads gene region information from the ANNOVAR file.\n",
    "Each line in the file contains a gene name along with its genomic location (chromosome, start, and stop positions).\n",
    "These regions are stored in a dictionary called gene_regions, where:\n",
    "\n",
    "The key is the gene name.\n",
    "\n",
    "The value is a list of one or more tuples, each representing a (chromosome, start, stop) for that gene. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files successfully loaded\n",
      "Loading ANNOVAR file\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/project/pi_rachel_melamed_uml_edu/neuroblastoma/maddie/double_checking/hg19_refGene.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading ANNOVAR file\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m gene_regions \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mannovar_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m annovar:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m annovar:\n\u001b[0;32m     17\u001b[0m         parts \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\OWNER\\anaconda3\\envs\\maddie\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/project/pi_rachel_melamed_uml_edu/neuroblastoma/maddie/double_checking/hg19_refGene.txt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File Paths\n",
    "base_path = \"/project/pi_rachel_melamed_uml_edu/neuroblastoma/maddie/double_checking/\"\n",
    "vcf_file = base_path + \"output_hg19.vcf\"\n",
    "burden_matrix_file = base_path + \"final_output_RVBurdenMatrix_0.9_0_nfe_rcc.txt\"  \n",
    "annovar_file = base_path + \"hg19_refGene.txt\"  \n",
    "\n",
    "print(\"Files successfully loaded\", flush=True)\n",
    "\n",
    "# Step 1: Load Gene Regions from ANNOVAR\n",
    "print(\"Loading ANNOVAR file\", flush=True)\n",
    "gene_regions = {}\n",
    "\n",
    "with open(annovar_file, 'r') as annovar:\n",
    "    for line in annovar:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) < 5:  # Skip malformed lines\n",
    "            continue\n",
    "        gene_name = parts[12]  # Gene name\n",
    "        chrom = parts[2]       # Chromosome\n",
    "        start = int(parts[4])  # Start position\n",
    "        stop = int(parts[5])   # Stop position\n",
    "\n",
    "        if gene_name not in gene_regions:\n",
    "            gene_regions[gene_name] = []  # Initialize list for regions\n",
    "        gene_regions[gene_name].append((chrom, start, stop)) # Add chrom start and stop to list\n",
    "\n",
    "print(f\"Loaded {len(gene_regions)} genes from ANNOVAR\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 \n",
    "\n",
    "Step 2 loads the variants from the VCF file.\n",
    "Each patient's variants are saved in a dictionary called patient_variants, where:\n",
    "\n",
    "The keys are patient IDs.\n",
    "\n",
    "The values are lists of tuples containing the chromosome and position of each variant that the patient carries. Only variants where the patient has at least one alternate allele (e.g., \"0/1\", \"1/1\", or \"1/2\") are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load Variants from VCF (ONLY Store Variants)\n",
    "print(\"Loading VCF file\", flush=True)\n",
    "patient_variants = {}  # {patient: [(chrom, pos), ...]}\n",
    "patient_ids = []\n",
    "\n",
    "with open(vcf_file, 'r') as vcf:\n",
    "    for line in vcf:\n",
    "        if line.startswith(\"#CHROM\"):\n",
    "            header_parts = line.strip().split(\"\\t\")\n",
    "            patient_ids = header_parts[9:]  # Extract patient IDs\n",
    "            for patient_id in patient_ids:\n",
    "                patient_variants[patient_id] = [] # Set patient ids as keys\n",
    "            continue\n",
    "\n",
    "        if line.startswith(\"#\"):\n",
    "            continue  # Skip header lines\n",
    "\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        chrom = parts[0]\n",
    "        pos = int(parts[1])\n",
    "        samples = parts[9:]\n",
    "\n",
    "        for idx, genotype in enumerate(samples): # Loops through each patients genotype\n",
    "            patient_id = patient_ids[idx] # Uses idx to get right patient id\n",
    "            genotype_value = genotype.split(\":\")[0]  # Extract only genotype (GT)\n",
    "\n",
    "            if \"1\" in genotype_value or \"2\" in genotype_value:\n",
    "                patient_variants[patient_id].append((chrom, pos))  # Store variant location\n",
    "\n",
    "print(f\"Loaded variants for {len(patient_variants)} patients from VCF\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3\n",
    "\n",
    "Step 3 loads in the burden matrix using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load Burden Matrix\n",
    "print(\"Loading Burden Matrix\", flush=True)\n",
    "burden_matrix = pd.read_csv(burden_matrix_file, sep=r\"\\s+\", index_col=0, engine=\"python\")\n",
    "\n",
    "print(f\"Loaded burden matrix with {burden_matrix.shape[0]} genes and {burden_matrix.shape[1]} patients\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4\n",
    "\n",
    "Step 4 validates the burden matrix by checking whether each reported variant for a gene is actually supported by the VCF data.\n",
    "\n",
    "First, it checks whether any patients listed in the burden matrix are missing from the VCF. If so, it prints a warning and skips those patients.\n",
    "\n",
    "Then, for each gene in the burden matrix, it:\n",
    "\n",
    "Cleans the gene name (in case it's a fusion gene, taking only the first part before a semicolon).\n",
    "\n",
    "Checks whether the burden matrix says the patient has a variant (1).\n",
    "\n",
    "If so, it checks whether the cleaned gene name exists in the ANNOVAR gene regions.\n",
    "\n",
    "If it does, it loops through each region for that gene and compares all of that patient's variant locations.\n",
    "\n",
    "If any of the patient’s variants fall within the gene’s start/stop region, it's considered a valid match.\n",
    "\n",
    "If a match is found, it’s added to the matches list. If not, it’s logged in the errors list as a mismatch between the burden matrix and VCF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Validate Burden Matrix Variants Using VCF\n",
    "errors = []\n",
    "matches = []\n",
    "\n",
    "print(\"Checking for mismatches between Burden Matrix and VCF...\", flush=True)\n",
    "\n",
    "for patient in burden_matrix.columns:\n",
    "    if patient not in patient_variants:  # If patient is missing in VCF, flag it\n",
    "        print(f\"Warning: Patient {patient} is in Burden Matrix but missing from VCF!\")\n",
    "        continue\n",
    "\n",
    "    for gene in burden_matrix.index:\n",
    "        cleaned_gene = gene.split(\";\")[0]  # Take the first gene name\n",
    "        reported_in_matrix = burden_matrix.loc[gene, patient]\n",
    "\n",
    "        # Only check genes marked as '1' (has a variant in burden matrix)\n",
    "        if reported_in_matrix == 1:\n",
    "            has_variant = False\n",
    "\n",
    "            # Check if the patient has a variant in the gene region\n",
    "            if cleaned_gene in gene_regions:\n",
    "                for chrom, start, stop in gene_regions[cleaned_gene]:\n",
    "                    for v_chrom, v_pos in patient_variants[patient]:\n",
    "                        if v_chrom == chrom and start <= v_pos <= stop:\n",
    "                            has_variant = True\n",
    "                            break\n",
    "                    if has_variant:\n",
    "                        break\n",
    "\n",
    "            # Log results\n",
    "            if has_variant:\n",
    "                matches.append(f\"Match: {patient} has a variant in {gene} (VCF & Burden Matrix)\")\n",
    "            else:\n",
    "                errors.append(f\"Mismatch: {patient} is marked as 1 in Burden Matrix but has no variant in VCF for {gene}\")\n",
    "\n",
    "print(\"Variant check completed.\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5\n",
    "\n",
    "Output matches and mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Print Matches & Errors\n",
    "if matches:\n",
    "    print(f\"Found {len(matches)} correct matches! Showing first 10:\")\n",
    "    for match in matches[:10]:\n",
    "        print(match)\n",
    "\n",
    "if errors:\n",
    "    print(f\"Found {len(errors)} mismatches! Showing first 10:\")\n",
    "    for error in errors[:10]:\n",
    "        print(error)\n",
    "else:\n",
    "    print(\"No mismatches found! Burden Matrix is consistent with VCF.\")\n",
    "\n",
    "print(\"Updated variant checking job completed.\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking allele counts\n",
    "\n",
    "Checking Allele Counts\n",
    "\n",
    "In this step, we calculate the total number of patients with a variant in each gene.\n",
    "\n",
    "First, we sum across each row of the burden matrix using .sum(axis=1), which gives us the total number of 1s per gene (i.e., the number of patients who have a variant in that gene).\n",
    "\n",
    "Then, we convert the resulting Series into a DataFrame with two columns: \"Gene\" and \"Allele_Count\".\n",
    "\n",
    "Finally, we save the allele counts to a tab-separated text file for downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Loading Burden Matrix...\", flush=True)\n",
    "\n",
    "# File Path to the Burden Matrix\n",
    "burden_matrix_file = \"/project/pi_rachel_melamed_uml_edu/neuroblastoma/maddie/double_checking/final_output_RVBurdenMatrix_0.9_0_nfe_rcc.txt\"\n",
    "\n",
    "# Load Burden Matrix\n",
    "burden_matrix = pd.read_csv(burden_matrix_file, sep=r\"\\s+\", index_col=0, engine=\"python\")\n",
    "\n",
    "print(f\"Loaded burden matrix with {burden_matrix.shape[0]} genes and {burden_matrix.shape[1]} patients\", flush=True)\n",
    "\n",
    "# Compute allele count per gene (sum across patient columns)\n",
    "allele_counts = burden_matrix.sum(axis=1)  \n",
    "\n",
    "# Convert to DataFrame\n",
    "allele_counts_df = allele_counts.reset_index()\n",
    "allele_counts_df.columns = [\"Gene\", \"Allele_Count\"]\n",
    "\n",
    "# Save to output file\n",
    "output_file = \"/project/pi_rachel_melamed_uml_edu/neuroblastoma/maddie/count_alleles/burden_matrix_allele_counts.txt\"\n",
    "allele_counts_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "# Print first 10 results\n",
    "print(\"Allele counts computed! First 10 genes:\")\n",
    "print(allele_counts_df.head(10))\n",
    "\n",
    "print(f\"Allele counts saved to: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maddie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
